{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import and initialize Pyspark environment\n",
    "\n",
    "Import Spark environment using findspark\n",
    "Initialize Spark environment\n",
    "Create SparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata  reviews\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./data/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies_and_TV.json.gz\r\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "\n",
    "ROOT_DIR = \"./\"\n",
    "DATA_DIR = path.join(ROOT_DIR, 'data')\n",
    "INPUT_DATA_PATH = path.join(DATA_DIR, 'input', 'reviews')\n",
    "!ls {INPUT_DATA_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.9:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f62dd91ab50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read data\n",
    "\n",
    "Read all the fields in the txt file by applying filter and map \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read JSON-formatted data file to dataframe\n",
    "\"\"\"\n",
    "\n",
    "data = spark.read.json(INPUT_DATA_PATH)\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+------------------+\n",
      "|summary|                asin|          reviewerID|           overall|\n",
      "+-------+--------------------+--------------------+------------------+\n",
      "|  count|             8765568|             8765568|           8765568|\n",
      "|   mean| 5.482090734266104E9|                null|4.2330105704501975|\n",
      "| stddev|2.0830512994750662E9|                null|1.2214384170933368|\n",
      "|    min|          0000143502|A00013803RVZPCZKTT9U|               1.0|\n",
      "|    max|          B01HJF79XO|       AZZZYAYJQSDOJ|               5.0|\n",
      "+-------+--------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get summary of the data\n",
    "To make sure there is no data incompliance \n",
    "\"\"\"\n",
    "\n",
    "data_used = data.select('asin', 'reviewerID', 'overall').dropna('any')\n",
    "summary = data_used.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-------+\n",
      "|asin|reviewerID|overall|\n",
      "+----+----------+-------+\n",
      "|   0|         0|      0|\n",
      "+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "data_used.select([count(when(isnan(c), c)).alias(c) for c in data_used.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3826085, 182032)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Apply count() to findout:\n",
    "\n",
    "    ` Number of movies\n",
    "    ` Number of users\n",
    "\"\"\"\n",
    "\n",
    "n_user = data_used.select('reviewerID').distinct().count()\n",
    "\n",
    "n_movie = data_used.select('asin').distinct().count()\n",
    "\n",
    "n_user, n_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|    reviewerID|count|\n",
      "+--------------+-----+\n",
      "| AVIKFXS6MT2YV|    2|\n",
      "|A3826GI7UHI7SZ|    9|\n",
      "|A33GM0OUOWK19O|    1|\n",
      "|A1687MV0PLK74B|   16|\n",
      "| AB64DUL65WO6O|   10|\n",
      "|A1FWW47TZ65PNY|    1|\n",
      "|A3RJ48YJJ3NOII|   18|\n",
      "|A1M0G9T633G1C3|    5|\n",
      "|A2QVL8FGY79WWH|    3|\n",
      "|A20TI7T43DCSRY|    2|\n",
      "|A343A2TZEZ9Y86|    1|\n",
      "| A6GMEO3VRY51S|  207|\n",
      "|A2DNWSXNZBD204|   23|\n",
      "| AZS14W9Q9XCUQ|    8|\n",
      "| AX3NVXGCTQ8AN|    1|\n",
      "| AYMM8AP7UVA8Y|    1|\n",
      "|A2E130DG40UA2L|   17|\n",
      "| ASWG8EJHCWPKC|   21|\n",
      "|A1UFEP3IOALM8V|    1|\n",
      "|A2BUPLL6RIQBRB|    1|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+-----+\n",
      "|      asin|count|\n",
      "+----------+-----+\n",
      "|0783218923|  150|\n",
      "|0783225911|  512|\n",
      "|6300185117|  155|\n",
      "|630025545X|   37|\n",
      "|6301008944|  741|\n",
      "|6301304977|   30|\n",
      "|630165191X|  229|\n",
      "|6301928482|   11|\n",
      "|6301929810|   40|\n",
      "|6301959728|  256|\n",
      "|6302405696|   19|\n",
      "|6302643635|   45|\n",
      "|6302676835|  109|\n",
      "|6302995779|   29|\n",
      "|6303026451|   30|\n",
      "|6303079709|  640|\n",
      "|6303150896|   27|\n",
      "|6303209785|   14|\n",
      "|6303223052|   21|\n",
      "|6303265774|  223|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Apply group by and count to findout:\n",
    "\n",
    "    ` Number of reviews from each user \n",
    "    ` Number of reviews each movie get\n",
    "\"\"\"\n",
    "\n",
    "nreview_by_user = data_used.groupBy('reviewerID').count()\n",
    "\n",
    "nreview_for_movie = data_used.groupBy('asin').count()\n",
    "\n",
    "nreview_by_user.show(), nreview_for_movie.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|    reviewerID|count|\n",
      "+--------------+-----+\n",
      "| AV6QDP8Q0ONK4| 4254|\n",
      "|A1GGOC9PVDXW7Z| 2292|\n",
      "|A328S9RN3U5M68| 2175|\n",
      "| ABO2ZI2Y5DQ9T| 2136|\n",
      "| AWG2O9C42XW5G| 2046|\n",
      "|A3MV1KKHX51FYT| 2017|\n",
      "|A2EDZH51XHFA9B| 1907|\n",
      "|A16CZRQL23NOIW| 1850|\n",
      "|A3LZGLA88K0LA0| 1826|\n",
      "|  AIMR915K4YCN| 1763|\n",
      "|A2NJO6YE954DBH| 1730|\n",
      "| ANCOMAI0I7LVG| 1667|\n",
      "|A20EEWWSFMZ1PN| 1666|\n",
      "|A1D2C0WDCSHUWZ| 1613|\n",
      "|A2HVL790PBWYTU| 1529|\n",
      "|A2YUA3H1LLU53Z| 1510|\n",
      "|A29TKSIWA3JKF3| 1411|\n",
      "|A19ZXK9HHVRV1X| 1336|\n",
      "|A2A7NHE5HTK79N| 1262|\n",
      "|A1NSDP9YZXLMDX| 1208|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "('Some of the most active users: ', None)\n",
      "+----------+-----+\n",
      "|      asin|count|\n",
      "+----------+-----+\n",
      "|B00YSG2ZPA|24558|\n",
      "|B00006CXSS|24489|\n",
      "|B000WGWQG8|23584|\n",
      "|B00AQVMZKQ|21015|\n",
      "|B01BHTSIOC|20889|\n",
      "|B00NAQ3EOK|16857|\n",
      "|6305837325|16671|\n",
      "|B00WNBABVC|15284|\n",
      "|B017S3OP7A|14795|\n",
      "|B009934S5M|14486|\n",
      "|B00FL31UF0|14174|\n",
      "|B014HDTT84|14158|\n",
      "|B00OGL6S64|14143|\n",
      "|B0002ERXC2|14007|\n",
      "|B00R8GUXPG|13761|\n",
      "|B00PY4Q9OS|13761|\n",
      "|B00Q0G2VXM|13741|\n",
      "|B00AS1Q8FW|12703|\n",
      "|B0063FQREO|12011|\n",
      "|B00543R3WG|11252|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "('Some of the most common movies: ', None)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Apply aggregation to findout: \n",
    "    ` Who are the most active users?\n",
    "    ` Wh bat is the most common movies?\n",
    "\"\"\"\n",
    "\n",
    "num = 10\n",
    "\n",
    "most_active = nreview_by_user.orderBy('count', ascending=False)\n",
    "\n",
    "most_common = nreview_for_movie.orderBy('count', ascending=False)\n",
    "\n",
    "print(\"Some of the most active users: \", most_active.show())\n",
    "print(\"Some of the most common movies: \", most_common.show())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data transformation and save\n",
    "\n",
    "We want to build a Recommendation system to suggest movies to users who might interested in based on their historical reviews. Rating score should be used. So we will make some information extracting and transforming job this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Store the ratings data as zipped csv \"\"\"\n",
    "\n",
    "target = os.path.join(DATA_DIR, 'ratings')\n",
    "\n",
    "data_used.write.json(target, mode='overwrite', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
